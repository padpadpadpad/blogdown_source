---
title: Doing local BLAST searches on sanger sequence data in R
author: "Daniel Padfield"
date: '2017-10-08'
slug: using-blast-on-sanger-sequences-in-r
categories: ["R"]
tags: ["sanger sequencing", "R", "BLAST", "genomics", "taxize"]
draft: yes
---

```{r, setup, echo = FALSE}
knitr::opts_knit$set(root.dir = normalizePath('../..'))
```

## Introduction

Moving to a microbiology group has meand I now have loads of interesting genomic and sequencing data to play with!

One common task we have when we start with some new natural communities is to work out what is in there! We plate the samples out, look at their colony morphology, but colonies can be picked and sequenced using sanger sequencing. Once you have your sequencing data back, you can check your sequence against a database to look at the taxonomic identity of the picked colonies.

I know that these sequences can be queried in [BLAST](https://blast.ncbi.nlm.nih.gov/Blast.cgi), where you enter a sequence and it returns matches from a database based on the percentage match. That is all pretty great but I am not about inputting 96 separate sequences into a website! So on Friday I explored the ways to do BLAST searches in a more automated way and came across [rBLAST](https://github.com/mhahsler/rBLAST). `rBLAST` is an R package that allows for local blast searches to be done in R.

This blog post is the culmination of about 5 hours coding that explains how you can go from sequences in a folder, to a dataframe of species names to each sequence. To do this I use `rBLAST` to run the local BLAST search, assign taxonomy using the `taxise` package, as well as some tidyverse tools from `dplyr`, `tidyr` and `purrr` to make everything work smoothly.

## 1. Get everything installed

Firstly everything that is used needs to be installed:
- BLAST+ needs to be installed externally from R. Advice and instructions for installation can be found [here](https://www.ncbi.nlm.nih.gov/books/NBK279671/)
- Install any packages available on CRAN using `install.packages(c("dplyr", "purrr", "tidyr")`
- Bioconductor provides tools for the analysis of high throughput genomic data. Some of the packages on their are not available on CRAN but can be installed using instructions on their [website](https://www.bioconductor.org/install/). Specifically we need to download `Biostrings` for `rBlast` to work.
- GitHub packages can be installed using `devtools::install_github()`. Install `rBLAST` using `devtools::install_github(mhahsler/rBLAST)`

Hopefully all the necessary packages to run local BLAST searches in R are now installed. Now we can load in some data!

## 2. Set up and loading in data

The output from sanger sequencing (although I am not well versed in it) appears to be one file per sample and all the output (including consensus scores) is present in .ab1 files. However I also received .seq files that acted as .txt files that stored the output of each sequence in. So in `file_1.seq` the output would be "CATGCAGTAGCT..." and so on.

I am going to use these .seq files to illustrate how to use rBLAST, but this script should be easily adaptable to file types as long as you can access each sequence!

```{r, load_packages, message = FALSE, warning = FALSE}
# load packages into R
library(rBLAST)
library(taxize)
library(dplyr)
library(tidyr)
library(purrr)
```

Then we want to list all the files in the data folder (because you keep all your raw data in separate folders and don't edit them under any circumstances... __RIGHT?!?__). As an aside, learn about good workflows in R [here](https://github.com/jdblischak/workflowr) or [here](https://swcarpentry.github.io/r-novice-gapminder/02-project-intro/).

```{r, list_files, eval = FALSE}
# list files in the data folder
seq_files <- list.files('raw_data', pattern = '.seq')

# store file path
seq_file_path <- 'where_your_files_are_saved'

# check they been found/we are in the right place
seq_files

# open a single file
read.table(file.path(seq_file_path,seq_file[1]), blank.lines.skip = TRUE, as.is = TRUE)

```

```{r, list_files_true, echo = FALSE}
# list files in the data folder
seq_files <- list.files('data/20171008_sanger/seq_files', pattern = '.seq', full.names = FALSE)
seq_file_path <- 'data/20171008_sanger/seq_files'

# check they been found/we are in the right place
seq_files

# open a single file
read.table(file.path(seq_file_path,seq_files[1]), blank.lines.skip = TRUE, as.is = TRUE)
```

So our sequence is there, all pretty and ready for alignment. However, to do local BLAST searches, we need to download a database to query our own sequences against. So we will download a 16S Microbial database from the ncbi website. This step only has to be done once and can be done within R, you just need to make a new folder (so the database files are in a separate folder) to extract the zipped files into.

```{r, download_database, eval = FALSE}
# download file
download.file(url = "ftp://ftp.ncbi.nlm.nih.gov/blast/db/16SMicrobial.tar.gz", destfile = "16SMicrobial.tar.gz", mode = 'wb')

# extract files from zipped file
untar("16SMicrobial.tar.gz", exdir = "blast_16SMicrobial_db")

# load database into R
bl <- blast(db = "blast_16SMicrobial_db/16SMicrobial")

```

```{r, load_database, echo = FALSE}
# load database into R
bl <- blast(db = "data/20171008_sanger/Blast_16SMicrobial_db/16SMicrobial")
```

We are now ready to do local BLAST searches on each file in our sequence folder, `seq_file_path`.

## 2. Run multiple local BLAST searches

It is common practice in R to do the same function over and over on multiple groups of a column (or elements in a vector) in R. For in my work I often take multiple .csv or .xlsx files, run them through a function where I grab only the information I want, and then bind them into a single dataframe. I used to use `plyr::ldply()` for this purpose but have recently moved across to `purrr::map_df()` as it is more compatible with `dplyr` and `tidyr`.

When going about this process, I first think what I want my output to be and then get the desired output for just a single file/element. Finally, if I can, I wrap the steps up in a function so that it can be rolled out again and again! There are loads of resources on [writing functions](http://adv-r.had.co.nz/Functions.html) and [debugging R code](https://stackoverflow.com/questions/4442518/general-suggestions-for-debugging-in-r) that should put you in the right direction for your own problems better than I can here.

In this example, we want a function that takes a single `.seq` file and returns a `data.frame` containing the BLAST search hit results.

```{r, rBLAST_all}
# function for a single local BLAST search for a single file
rBLAST_all <- function(seq_file, database, keep = 0.95){
  
  # read in and create single sequence line
  test <- read.table(seq_file, blank.lines.skip = TRUE, as.is = TRUE)
  seq1 <- paste(test$V1, collapse = '')
  
  # make a string set necessary for rBLAST and name file
  seq2 <- Biostrings::BStringSet(seq1)
  names(seq2) <- basename(seq_file)
  
  # use rBLAST and add sequence to subsequent dataframe
  seq_pred <- predict(database, seq2) %>%
    dplyr::filter(., Perc.Ident > keep*100) %>%
    dplyr::mutate_at(., c('QueryID', 'SubjectID'), as.character) %>%
    dplyr::mutate(seq = seq1)
  
  # return dataframe  
  return(seq_pred)
}
```

This function takes a single file, e.g. `file_1.seq`, reads it in and gets the sequence. It then makes the dataset into a `DNAStringSet`, a special object type in R that rBLAST needs the sequence to be in. I then also assigned the name of the file to the sequence so each row in the final data frame has an identifier.

I then call `rBLAST` and do local BLAST alignment on the sequence using its `predict()` function. I have added a parameter, `keep`, that controls the % similarity of the hits to retain in the dataframe. Anything under that proportion will be discarded.

The key to adapting this function for your own needs is to get the desired input and output of your start file, Once you've read in one of your files and made it a `DNAStringSet` running them through BLAST should be ok.

We can run this function on a single file and see if the output is what we want.

```{r, single_run}
# run on the first file
test <- rBLAST_all(file.path(seq_file_path, seq_files[1]), database = bl)

# look at names of columnes
names(test)

# look at first 6 rows of data, seq column removed (LONG!)
head(select(test, -seq))
```

__Yay!__ A dataframe of alignments much like you would see in BLAST. Pretty amazing. We can then run that function on all of our `.seq` files using `purrr::map_df()`.

```{r, run_rBlast_all}
# update our files to have the full names
seq_files = paste(seq_file_path, seq_files, sep = '/')

# run rBlast all
seq_IDs <- purrr::map_df(seq_files, rBLAST_all, database = bl, keep = 0.97) %>%
  # create column for nrow
  mutate(., num = 1:n())

# check number of rows
nrow(seq_IDs)
```

This returns a dataframe of 54 hits across the 7 samples. The local BLAST alignments only return a `SubjectID` by default, which is the GenBankID number, but we want the species name of each sequence! 

I am going to demonstrate how this can be done using the R package `taxize`, that uses the NCBI API to get the taxonomy information.

## 3. Using taxize to get taxonomy

The R package `taxize` interacts with a suite of web APIs for taxonomic jobs, such as getting database specific taxonomic identifiers, verifying species names and (__importantly__), getting species names from database IDs. A great tutorial and overview of `taxise` is on the [rOpenSci website](https://ropensci.org/tutorials/taxize_tutorial.html).

As `SubjectID` in our dataframe is a GenBankID, we need to get the NCBI taxonomy UID for each of these and then get the taxonomy. `taxize` has functions to do this. To go from GenBankID -> UID we shall use `taxize::genbank2uid()`. To go from UID -> taxonomy we shall use `taxize::ncbi_get_taxon_summary`. To do the same function on row of our dataframe, I nested some of my data in a list within my existing dataframe. This gives a list column that I can use `purrr::map()` to add another list column to my dataframe, before unnesting them both again! If this sounds complex, you are not alone (and this is the first time I did it this way too), but I did find a couple of great examples on list columns, purrr and dplyr [here](https://jennybc.github.io/purrr-tutorial/ls13_list-columns.html) and [here](http://ijlyttle.github.io/isugg_purrr/presentation.html#(1)). Here, this method helps ensure a single API call is used for each row of the dataframe and helps us control for possible errors, using `purrr::possibly()`.

```{r, GenbankID_2_UID, warning = FALSE}
# reduce number of columns so we drop all of the gumph
seq_IDs <- select(seq_IDs, num, QueryID, SubjectID, Perc.Ident)

# work out the uid from the genbank id - given as SubjectID
# approach - nest each row in a list and call the API separately - return NA if it does not work
seq_IDs_nest <- seq_IDs %>%
  nest(., SubjectID) %>%
  mutate(., uid = map(data, possibly(genbank2uid, otherwise = NA, quiet = TRUE)))

# unnest these columns to get the dataframes out. There shall be warnings but they are ok as the correct uids are preserved
seq_IDs <- seq_IDs_nest %>%
  unnest(data, uid)

head(seq_IDs)

```

Now we have the NCBI taxon summary ID, we can go ahead and get the taxonomy of each row, in much the same way as we got the NCBI taxon summary ID from the GenBank ID.

```{r, UID_taxonomy, warning = FALSE}
# now nest uids of each row and run the get_taxon_summary API call on each list element
seq_IDs_nest <- seq_IDs %>%
  nest(., uid) %>%
  mutate(., tax_info = map(data, possibly(ncbi_get_taxon_summary, otherwise = NA, quiet = TRUE)))

# unnest this dataframe for final dataframe of what everything is
seq_IDs <- seq_IDs_nest %>%
  unnest(tax_info) %>%
  select(., -data)

# lets have a look
head(seq_IDs)
```

And there you have it. We have a dataframe that now includes the species name of each of the returned hits for each file. Pretty neat if you ask me, and better than clicking over and over in BLAST on their website! This script is now ready to go again and again. Not bad for around 5 hours work! From this we can examine consensus within samples and look for variation across samples. The opportunities are endless.

Thanks for reading. A script containing only the code chunks used here can be found [here](https://gist.github.com/padpadpadpad/d2fe494b8392d0c84b40fe158caca834) and the files can be found in the `data/20171008_sanger` folder of my [GitHub blogdown repository](https://github.com/padpadpadpad/blogdown_source) if you want to run through my example completely. You will just have to change the directories where the files are (or preferably use R projects)!
